{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import librairies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.3)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install scikit-learn\n",
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time  \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10111, 3)\n",
      "(23593, 3)\n",
      "(33704, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_final = pd.read_csv('/workspace/data/final_diag10.csv')\n",
    "#batching data into samples\n",
    "df_final1 = df_final.sample(frac=0.3)\n",
    "df_final2 = df_final.sample(frac=0.7)\n",
    "df_final3 = df_final.sample(frac=1)\n",
    "#checking size\n",
    "print(df_final1.shape)\n",
    "print(df_final2.shape)\n",
    "print(df_final3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 30% of the dataset\n",
    "data1 = df_final1.copy()\n",
    "# Load 70% of the dataset\n",
    "data2 = df_final2.copy()\n",
    "# Load full dataset\n",
    "data3 = df_final3.copy()\n",
    "#train/test split was 80/20%\n",
    "# Split the dataset into training and testing sets\n",
    "train_df1, test_df1 = train_test_split(data1, test_size=0.2, random_state=42)\n",
    "train_df2, test_df2 = train_test_split(data2, test_size=0.2, random_state=42)\n",
    "train_df3, test_df3 = train_test_split(data3, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the ClinicalBERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    return tokenizer(texts, padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "train_encodings1 = tokenize_texts(train_df1['clean_text'].tolist())\n",
    "test_encodings1 = tokenize_texts(test_df1['clean_text'].tolist())\n",
    "train_encodings2 = tokenize_texts(train_df2['clean_text'].tolist())\n",
    "test_encodings2 = tokenize_texts(test_df2['clean_text'].tolist())\n",
    "train_encodings3 = tokenize_texts(train_df3['clean_text'].tolist())\n",
    "test_encodings3 = tokenize_texts(test_df3['clean_text'].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on first sample=30% dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = TextDataset(train_encodings1, train_df1['labels'].tolist())\n",
    "test_dataset = TextDataset(test_encodings1, test_df1['labels'].tolist())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Setting models definition\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.rnn(embedded)\n",
    "        return self.fc(output[:, -1, :])\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.lstm(embedded)\n",
    "        return self.fc(output[:, -1, :])\n",
    "\n",
    "class BERTForClassification(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, output_dim)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        return self.fc(outputs['pooler_output'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Time: 4.541696548461914 seconds, Testing Time: 0.5304920673370361 seconds\n",
      "Epoch: 1, Training Time: 4.363293886184692 seconds, Testing Time: 0.5299208164215088 seconds\n",
      "Epoch: 2, Training Time: 4.361943960189819 seconds, Testing Time: 0.5304784774780273 seconds\n",
      "Epoch: 3, Training Time: 4.3600006103515625 seconds, Testing Time: 0.5308542251586914 seconds\n",
      "Epoch: 4, Training Time: 4.360978841781616 seconds, Testing Time: 0.5304121971130371 seconds\n",
      "Epoch: 5, Training Time: 4.3587048053741455 seconds, Testing Time: 0.5310385227203369 seconds\n",
      "Epoch: 6, Training Time: 4.361249923706055 seconds, Testing Time: 0.5299441814422607 seconds\n",
      "Epoch: 7, Training Time: 4.359501123428345 seconds, Testing Time: 0.5310101509094238 seconds\n",
      "Epoch: 8, Training Time: 4.359088182449341 seconds, Testing Time: 0.5295190811157227 seconds\n",
      "Epoch: 9, Training Time: 4.359435558319092 seconds, Testing Time: 0.530311107635498 seconds\n",
      "Training completed.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.19      0.24       596\n",
      "           1       0.08      0.07      0.08       207\n",
      "           2       0.12      0.10      0.10       221\n",
      "           3       0.09      0.25      0.13       109\n",
      "           4       0.12      0.13      0.13       106\n",
      "           5       0.09      0.09      0.09       163\n",
      "           6       0.09      0.14      0.11       126\n",
      "           7       0.20      0.17      0.19       359\n",
      "           8       0.08      0.09      0.08       117\n",
      "           9       0.03      0.11      0.04        19\n",
      "\n",
      "    accuracy                           0.15      2023\n",
      "   macro avg       0.12      0.13      0.12      2023\n",
      "weighted avg       0.18      0.15      0.16      2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RNN Tuned MODEL FOR SAMPLE 1\n",
    "import warnings\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class AdjustedRNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout=0.4):\n",
    "        super(AdjustedRNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)  # Use nn.RNN instead of nn.LSTM\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        rnn_out, _ = self.rnn(embedded)  # Use rnn_out instead of lstm_out\n",
    "        # Use the last hidden state for classification\n",
    "        output = self.fc(self.dropout(rnn_out[:, -1, :]))\n",
    "        return output\n",
    "\n",
    "# Instantiate model\n",
    "model = AdjustedRNNModel(vocab_size=tokenizer.vocab_size, embedding_dim=128, hidden_dim=256, output_dim=10, dropout=0.4).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.00002)\n",
    "\n",
    "\n",
    "# Assuming `train_labels` is a list containing all the labels in your training dataset\n",
    "train_labels = [label for batch in train_loader for label in batch['labels'].tolist()]\n",
    "\n",
    "# 1. Compute class distribution\n",
    "class_counts = Counter(train_labels)\n",
    "\n",
    "# 2. Calculate the weights\n",
    "max_count = max(class_counts.values())\n",
    "class_weights = {class_id: max_count / count for class_id, count in class_counts.items()}\n",
    "weights = [class_weights[class_id] for class_id in sorted(class_weights.keys())]\n",
    "\n",
    "weights_tensor = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# 3. Use the weights in the loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()  # use this if data is not imbalanced\n",
    "\n",
    "# Add Learning Rate Scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "# Train the model\n",
    "best_f1 = 0.0  # for early stopping based on F1 score\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Measure the time at the start of the epoch\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    training_start_time = time.time()  # Start measuring time\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    training_end_time = time.time()  # End measuring time\n",
    "    training_time = training_end_time - training_start_time  # Calculate elapsed time for training\n",
    "\n",
    "    model.eval()\n",
    "    testing_start_time = time.time()  # Start measuring time\n",
    "    predictions, true_labels = [], []\n",
    "    val_loss = 0  # to compute average validation loss for scheduler\n",
    "\n",
    "    for batch in test_loader:\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            predictions.extend(torch.argmax(outputs, dim=1).cpu().tolist())\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "    testing_end_time = time.time()  # End measuring time\n",
    "    testing_time = testing_end_time - testing_start_time  # Calculate elapsed time for testing\n",
    "\n",
    "    val_f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    scheduler.step(val_loss / len(test_loader))  # scheduler step based on avg val loss\n",
    "    report1 = classification_report(true_labels, predictions)\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Training Time: {training_time} seconds, Testing Time: {testing_time} seconds\")\n",
    "    \n",
    "    #print(report)\n",
    "    \n",
    "    # Implementing early stopping based on F1 score\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        #torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= 3:\n",
    "            print(\"Early stopping\")\n",
    "            print(report1)\n",
    "            break\n",
    "            \n",
    "else:  # This block will be executed if the for loop completes normally, i.e., if early stopping does not occur.\n",
    "    print(\"Training completed.\")\n",
    "    print(report1)  # Print the classification report after the last epoch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Time: 13.198179006576538 seconds, Testing Time: 1.5351340770721436 seconds\n",
      "Epoch: 1, Training Time: 13.199532508850098 seconds, Testing Time: 1.5354061126708984 seconds\n",
      "Epoch: 2, Training Time: 13.208195447921753 seconds, Testing Time: 1.535597324371338 seconds\n",
      "Epoch: 3, Training Time: 13.208856344223022 seconds, Testing Time: 1.5362322330474854 seconds\n",
      "Epoch: 4, Training Time: 13.207075595855713 seconds, Testing Time: 1.5366137027740479 seconds\n",
      "Epoch: 5, Training Time: 13.207062482833862 seconds, Testing Time: 1.53670334815979 seconds\n",
      "Epoch: 6, Training Time: 13.211395263671875 seconds, Testing Time: 1.5366365909576416 seconds\n",
      "Epoch: 7, Training Time: 13.210636615753174 seconds, Testing Time: 1.5361075401306152 seconds\n",
      "Early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.14      0.21       596\n",
      "           1       0.44      0.32      0.37       207\n",
      "           2       0.59      0.39      0.47       221\n",
      "           3       0.35      0.39      0.37       109\n",
      "           4       0.36      0.74      0.48       106\n",
      "           5       0.12      0.61      0.20       163\n",
      "           6       0.14      0.04      0.06       126\n",
      "           7       0.25      0.08      0.12       359\n",
      "           8       0.29      0.50      0.37       117\n",
      "           9       0.95      1.00      0.97        19\n",
      "\n",
      "    accuracy                           0.28      2023\n",
      "   macro avg       0.39      0.42      0.36      2023\n",
      "weighted avg       0.36      0.28      0.27      2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##LSTM tined MODEL FOR SAMPLE 1\n",
    "import warnings\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class AdjustedLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout=0.2):\n",
    "        super(AdjustedLSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Use the last hidden state for classification\n",
    "        output = self.fc(self.dropout(lstm_out[:, -1, :]))\n",
    "        return output\n",
    "\n",
    "# Instantiate model\n",
    "model = AdjustedLSTMModel(vocab_size=tokenizer.vocab_size, embedding_dim=128, hidden_dim=256, output_dim=10, dropout=0.2).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(),lr=0.001)\n",
    "\n",
    "# If your dataset is imbalanced, compute class weights\n",
    "# weights = # Compute based on class distribution\n",
    "# criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "\n",
    "# Assuming `train_labels` is a list containing all the labels in your training dataset\n",
    "train_labels = [label for batch in train_loader for label in batch['labels'].tolist()]\n",
    "\n",
    "# 1. Compute class distribution\n",
    "class_counts = Counter(train_labels)\n",
    "\n",
    "# 2. Calculate the weights\n",
    "max_count = max(class_counts.values())\n",
    "class_weights = {class_id: max_count / count for class_id, count in class_counts.items()}\n",
    "weights = [class_weights[class_id] for class_id in sorted(class_weights.keys())]\n",
    "\n",
    "weights_tensor = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# 3. Use the weights in the loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()  # use this if data is not imbalanced\n",
    "\n",
    "# Add Learning Rate Scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "# Train the model\n",
    "best_f1 = 0.0  # for early stopping based on F1 score\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    training_start_time = time.time()  # Start measuring time\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    training_end_time = time.time()  # End measuring time\n",
    "    training_time = training_end_time - training_start_time  # Calculate elapsed time for training\n",
    "\n",
    "    model.eval()\n",
    "    testing_start_time = time.time()  # Start measuring time\n",
    "    predictions, true_labels = [], []\n",
    "    val_loss = 0  # to compute average validation loss for scheduler\n",
    "\n",
    "    for batch in test_loader:\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            predictions.extend(torch.argmax(outputs, dim=1).cpu().tolist())\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "    testing_end_time = time.time()  # End measuring time\n",
    "    testing_time = testing_end_time - testing_start_time  # Calculate elapsed time for testing\n",
    "\n",
    "    val_f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    scheduler.step(val_loss / len(test_loader))  # scheduler step based on avg val loss\n",
    "    report2 = classification_report(true_labels, predictions)\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Training Time: {training_time} seconds, Testing Time: {testing_time} seconds\")\n",
    "    # Implementing early stopping based on F1 score\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        #torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= 3:\n",
    "            print(\"Early stopping\")\n",
    "            print(report2)\n",
    "            \n",
    "            break  # Exit the loop if patience_counter exceeds the limit\n",
    "else:  # This block will be executed if the for loop completes normally, i.e., if early stopping does not occur.\n",
    "    print(\"Training completed.\")\n",
    "    print(report2)  # Print the classification report after the last epoch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Time: 14.084446668624878 seconds, Testing Time: 1.534104585647583 seconds\n",
      "Epoch: 1, Training Time: 14.099526643753052 seconds, Testing Time: 1.5337960720062256 seconds\n",
      "Epoch: 2, Training Time: 14.101390361785889 seconds, Testing Time: 1.5349996089935303 seconds\n",
      "Epoch: 3, Training Time: 14.145069599151611 seconds, Testing Time: 1.5351905822753906 seconds\n",
      "Epoch: 4, Training Time: 14.132375955581665 seconds, Testing Time: 1.5357341766357422 seconds\n",
      "Epoch: 5, Training Time: 14.127297401428223 seconds, Testing Time: 1.5351934432983398 seconds\n",
      "Epoch: 6, Training Time: 14.126686096191406 seconds, Testing Time: 1.534231424331665 seconds\n",
      "Epoch: 7, Training Time: 14.122629642486572 seconds, Testing Time: 1.535069465637207 seconds\n",
      "Epoch: 8, Training Time: 14.112920761108398 seconds, Testing Time: 1.5343022346496582 seconds\n",
      "Epoch: 9, Training Time: 14.121893644332886 seconds, Testing Time: 1.5345916748046875 seconds\n",
      "Training completed.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.52      0.56       596\n",
      "           1       0.54      0.50      0.52       207\n",
      "           2       0.70      0.67      0.69       221\n",
      "           3       0.76      0.83      0.79       109\n",
      "           4       0.77      0.80      0.79       106\n",
      "           5       0.30      0.33      0.31       163\n",
      "           6       0.31      0.27      0.29       126\n",
      "           7       0.44      0.55      0.49       359\n",
      "           8       0.64      0.69      0.66       117\n",
      "           9       0.95      0.95      0.95        19\n",
      "\n",
      "    accuracy                           0.55      2023\n",
      "   macro avg       0.60      0.61      0.60      2023\n",
      "weighted avg       0.56      0.55      0.55      2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##BiLSTM tuned MODEL FOR SAMPLE 1\n",
    "import warnings\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "class AdjustedBiLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout=0.2):\n",
    "        super(AdjustedBiLSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Add this line to store the hidden_dim as an instance variable\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(2*hidden_dim, output_dim)  # Multiply by 2 because it's bidirectional\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Use the last hidden state for classification. We concatenate the last hidden state from both directions\n",
    "        output = self.fc(self.dropout(torch.cat((lstm_out[:, -1, :self.hidden_dim], lstm_out[:, 0, self.hidden_dim:]), dim=1)))\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate model\n",
    "model = AdjustedBiLSTMModel(vocab_size=tokenizer.vocab_size, embedding_dim=128, hidden_dim=256, output_dim=10, dropout=0.2).to(device)\n",
    "\n",
    "#model = AdjustedLSTMModel(vocab_size=tokenizer.vocab_size, embedding_dim=128, hidden_dim=256, output_dim=10, dropout=0.2).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(),lr=0.001)\n",
    "\n",
    "# If your dataset is imbalanced, compute class weights\n",
    "# weights = # Compute based on class distribution\n",
    "# criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "\n",
    "# Assuming `train_labels` is a list containing all the labels in your training dataset\n",
    "train_labels = [label for batch in train_loader for label in batch['labels'].tolist()]\n",
    "\n",
    "# 1. Compute class distribution\n",
    "class_counts = Counter(train_labels)\n",
    "\n",
    "# 2. Calculate the weights\n",
    "max_count = max(class_counts.values())\n",
    "class_weights = {class_id: max_count / count for class_id, count in class_counts.items()}\n",
    "weights = [class_weights[class_id] for class_id in sorted(class_weights.keys())]\n",
    "\n",
    "weights_tensor = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# 3. Use the weights in the loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()  # use this if data is not imbalanced\n",
    "\n",
    "# Add Learning Rate Scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "# Train the model\n",
    "best_f1 = 0.0  # for early stopping based on F1 score\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    training_start_time = time.time()  # Start measuring time\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    training_end_time = time.time()  # End measuring time\n",
    "    training_time = training_end_time - training_start_time  # Calculate elapsed time for training\n",
    "\n",
    "    model.eval()\n",
    "    testing_start_time = time.time()  # Start measuring time\n",
    "    predictions, true_labels = [], []\n",
    "    val_loss = 0  # to compute average validation loss for scheduler\n",
    "\n",
    "    for batch in test_loader:\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            predictions.extend(torch.argmax(outputs, dim=1).cpu().tolist())\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "    testing_end_time = time.time()  # End measuring time\n",
    "    testing_time = testing_end_time - testing_start_time  # Calculate elapsed time for testing\n",
    "\n",
    "    val_f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    scheduler.step(val_loss / len(test_loader))  # scheduler step based on avg val loss\n",
    "    report3 = classification_report(true_labels, predictions)\n",
    "    #print(f\"Epoch: {epoch}, F1 Score: {val_f1}\")\n",
    "            # Measure the time at the end of the epoch and calculate the total epoch time\n",
    "    print(f\"Epoch: {epoch}, Training Time: {training_time} seconds, Testing Time: {testing_time} seconds\")\n",
    "    \n",
    "    # Implementing early stopping based on F1 score\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        #torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= 3:\n",
    "            print(\"Early stopping\")\n",
    "            print(report3)\n",
    "            break\n",
    "            \n",
    "else:  # This block will be executed if the for loop completes normally, i.e., if early stopping does not occur.\n",
    "    print(\"Training completed.\")\n",
    "    print(report3)  # Print the classification report after the last epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Time: 945.988831281662 seconds, Testing Time: 88.88681030273438 seconds\n",
      "Epoch: 1, Training Time: 1067.7041203975677 seconds, Testing Time: 104.17880487442017 seconds\n",
      "Epoch: 2, Training Time: 1156.3965866565704 seconds, Testing Time: 116.53806471824646 seconds\n",
      "Epoch: 3, Training Time: 1264.6754972934723 seconds, Testing Time: 186.50725984573364 seconds\n",
      "Early stopping triggered.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       596\n",
      "           1       0.80      0.68      0.74       207\n",
      "           2       0.78      0.92      0.84       221\n",
      "           3       0.92      0.82      0.86       109\n",
      "           4       0.85      0.96      0.90       106\n",
      "           5       0.66      0.55      0.60       163\n",
      "           6       0.45      0.52      0.48       126\n",
      "           7       0.72      0.76      0.74       359\n",
      "           8       0.83      0.85      0.84       117\n",
      "           9       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           0.77      2023\n",
      "   macro avg       0.79      0.79      0.78      2023\n",
      "weighted avg       0.78      0.77      0.77      2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##BERT MODEL FOR SAMPLE 1\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = BERTForClassification(10).to(device)  # replace NUM_CLASSES with the number of unique labels in your dataset\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 3\n",
    "best_valid_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    training_start_time = time.time()  # Start measuring time\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        inputs, attention_mask, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['labels'].to(device)\n",
    "        outputs = model(inputs, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    training_end_time = time.time()  # End measuring time\n",
    "    training_time = training_end_time - training_start_time  # Calculate elapsed time for training\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    testing_start_time = time.time()  # Start measuring time\n",
    "    predictions, true_labels = [], []\n",
    "    for batch in test_loader:\n",
    "        with torch.no_grad():\n",
    "            inputs, attention_mask, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['labels'].to(device)\n",
    "            outputs = model(inputs, attention_mask)\n",
    "            predictions.extend(torch.argmax(outputs, dim=1).cpu().tolist())\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "    testing_end_time = time.time()  # End measuring time\n",
    "    testing_time = testing_end_time - testing_start_time  # Calculate elapsed time for testing\n",
    "\n",
    "    val_f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    report4 = classification_report(true_labels, predictions)\n",
    "    #print(f\"Epoch: {epoch}, F1 Score for sample1: {val_f1}\")\n",
    "    # Measure the time at the end of the epoch and calculate the total epoch time\n",
    "    print(f\"Epoch: {epoch}, Training Time: {training_time} seconds, Testing Time: {testing_time} seconds\")\n",
    "    # Early stopping logic\n",
    "    if val_f1 < best_valid_loss:\n",
    "        best_valid_loss = val_f1\n",
    "        counter = 0\n",
    "        #torch.save(model.state_dict(), 'best_model_bert2.pkl')  # Save the model\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            print(report4)\n",
    "            break\n",
    "            \n",
    "else:  # This block will be executed if the for loop completes normally, i.e., if early stopping does not occur.\n",
    "    print(\"Training completed.\")\n",
    "    print(report4)  # Print the classification report after the last epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on first sample=70% dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(train_encodings2, train_df2['labels'].tolist())\n",
    "test_dataset = TextDataset(test_encodings2, test_df2['labels'].tolist())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Time: 57.0829803943634 seconds, Testing Time: 9.094545125961304 seconds\n",
      "Epoch: 1, Training Time: 56.624675035476685 seconds, Testing Time: 9.064682722091675 seconds\n",
      "Epoch: 2, Training Time: 56.65733861923218 seconds, Testing Time: 9.00195837020874 seconds\n",
      "Epoch: 3, Training Time: 56.8730583190918 seconds, Testing Time: 9.017818450927734 seconds\n",
      "Epoch: 4, Training Time: 56.736207485198975 seconds, Testing Time: 9.016145944595337 seconds\n",
      "Epoch: 5, Training Time: 56.97301697731018 seconds, Testing Time: 9.023436784744263 seconds\n",
      "Epoch: 6, Training Time: 57.03428077697754 seconds, Testing Time: 9.010648012161255 seconds\n",
      "Epoch: 7, Training Time: 57.14561605453491 seconds, Testing Time: 9.0681471824646 seconds\n",
      "Epoch: 8, Training Time: 57.098625898361206 seconds, Testing Time: 9.121687412261963 seconds\n",
      "Epoch: 9, Training Time: 57.15428137779236 seconds, Testing Time: 9.118422746658325 seconds\n",
      "Training completed.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.31      0.33      1360\n",
      "           1       0.17      0.09      0.12       506\n",
      "           2       0.36      0.30      0.33       569\n",
      "           3       0.09      0.07      0.08       227\n",
      "           4       0.11      0.11      0.11       267\n",
      "           5       0.12      0.14      0.13       407\n",
      "           6       0.05      0.05      0.05       270\n",
      "           7       0.23      0.30      0.26       786\n",
      "           8       0.08      0.09      0.08       283\n",
      "           9       0.08      0.43      0.13        44\n",
      "\n",
      "    accuracy                           0.22      4719\n",
      "   macro avg       0.16      0.19      0.16      4719\n",
      "weighted avg       0.23      0.22      0.22      4719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RNN Tuned MODEL FOR SAMPLE 2\n",
    "import warnings\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class AdjustedRNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout=0.4):\n",
    "        super(AdjustedRNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)  # Use nn.RNN instead of nn.LSTM\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        rnn_out, _ = self.rnn(embedded)  # Use rnn_out instead of lstm_out\n",
    "        # Use the last hidden state for classification\n",
    "        output = self.fc(self.dropout(rnn_out[:, -1, :]))\n",
    "        return output\n",
    "\n",
    "# Instantiate model\n",
    "model = AdjustedRNNModel(vocab_size=tokenizer.vocab_size, embedding_dim=128, hidden_dim=256, output_dim=10, dropout=0.4).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.00002)\n",
    "\n",
    "\n",
    "# Assuming `train_labels` is a list containing all the labels in your training dataset\n",
    "train_labels = [label for batch in train_loader for label in batch['labels'].tolist()]\n",
    "\n",
    "# 1. Compute class distribution\n",
    "class_counts = Counter(train_labels)\n",
    "\n",
    "# 2. Calculate the weights\n",
    "max_count = max(class_counts.values())\n",
    "class_weights = {class_id: max_count / count for class_id, count in class_counts.items()}\n",
    "weights = [class_weights[class_id] for class_id in sorted(class_weights.keys())]\n",
    "\n",
    "weights_tensor = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# 3. Use the weights in the loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()  # use this if data is not imbalanced\n",
    "\n",
    "# Add Learning Rate Scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "# Train the model\n",
    "best_f1 = 0.0  # for early stopping based on F1 score\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Measure the time at the start of the epoch\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    training_start_time = time.time()  # Start measuring time\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    training_end_time = time.time()  # End measuring time\n",
    "    training_time = training_end_time - training_start_time  # Calculate elapsed time for training\n",
    "\n",
    "    model.eval()\n",
    "    testing_start_time = time.time()  # Start measuring time\n",
    "    predictions, true_labels = [], []\n",
    "    val_loss = 0  # to compute average validation loss for scheduler\n",
    "\n",
    "    for batch in test_loader:\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            predictions.extend(torch.argmax(outputs, dim=1).cpu().tolist())\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "    testing_end_time = time.time()  # End measuring time\n",
    "    testing_time = testing_end_time - testing_start_time  # Calculate elapsed time for testing\n",
    "\n",
    "    val_f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    scheduler.step(val_loss / len(test_loader))  # scheduler step based on avg val loss\n",
    "    report5 = classification_report(true_labels, predictions)\n",
    "    #print(f\"Epoch: {epoch}, F1 Score: {val_f1}\")\n",
    "        # Measure the time at the end of the epoch and calculate the total epoch time\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, Training Time: {training_time} seconds, Testing Time: {testing_time} seconds\")\n",
    "    \n",
    "    # Implementing early stopping based on F1 score\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        #torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= 3:\n",
    "            print(\"Early stopping\")\n",
    "            print(report5)\n",
    "            break\n",
    "            \n",
    "else:  # This block will be executed if the for loop completes normally, i.e., if early stopping does not occur.\n",
    "    print(\"Training completed.\")\n",
    "    print(report5)  # Print the classification report after the last epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Time: 141.80748558044434 seconds, Testing Time: 18.859255075454712 seconds\n",
      "Epoch: 1, Training Time: 141.75663423538208 seconds, Testing Time: 18.7702374458313 seconds\n",
      "Epoch: 2, Training Time: 140.7245569229126 seconds, Testing Time: 18.531009912490845 seconds\n",
      "Epoch: 3, Training Time: 140.87819862365723 seconds, Testing Time: 18.686228275299072 seconds\n",
      "Epoch: 4, Training Time: 141.34877490997314 seconds, Testing Time: 18.936192512512207 seconds\n",
      "Epoch: 5, Training Time: 141.31698036193848 seconds, Testing Time: 18.768061876296997 seconds\n",
      "Epoch: 6, Training Time: 141.2521812915802 seconds, Testing Time: 18.670800924301147 seconds\n",
      "Epoch: 7, Training Time: 141.54669332504272 seconds, Testing Time: 18.845343112945557 seconds\n",
      "Epoch: 8, Training Time: 142.21890544891357 seconds, Testing Time: 18.731409549713135 seconds\n",
      "Epoch: 9, Training Time: 147.49264073371887 seconds, Testing Time: 20.34921884536743 seconds\n",
      "Training completed.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73      1360\n",
      "           1       0.68      0.75      0.72       506\n",
      "           2       0.87      0.71      0.78       569\n",
      "           3       0.70      0.89      0.79       227\n",
      "           4       0.93      0.91      0.92       267\n",
      "           5       0.54      0.66      0.60       407\n",
      "           6       0.42      0.70      0.52       270\n",
      "           7       0.77      0.55      0.64       786\n",
      "           8       0.82      0.86      0.84       283\n",
      "           9       1.00      0.89      0.94        44\n",
      "\n",
      "    accuracy                           0.71      4719\n",
      "   macro avg       0.75      0.76      0.75      4719\n",
      "weighted avg       0.74      0.71      0.72      4719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##LSTM tined MODEL FOR SAMPLE 1\n",
    "import warnings\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class AdjustedLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout=0.2):\n",
    "        super(AdjustedLSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Use the last hidden state for classification\n",
    "        output = self.fc(self.dropout(lstm_out[:, -1, :]))\n",
    "        return output\n",
    "\n",
    "# Instantiate model\n",
    "model = AdjustedLSTMModel(vocab_size=tokenizer.vocab_size, embedding_dim=128, hidden_dim=256, output_dim=10, dropout=0.2).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(),lr=0.001)\n",
    "\n",
    "# If your dataset is imbalanced, compute class weights\n",
    "# weights = # Compute based on class distribution\n",
    "# criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "\n",
    "# Assuming `train_labels` is a list containing all the labels in your training dataset\n",
    "train_labels = [label for batch in train_loader for label in batch['labels'].tolist()]\n",
    "\n",
    "# 1. Compute class distribution\n",
    "class_counts = Counter(train_labels)\n",
    "\n",
    "# 2. Calculate the weights\n",
    "max_count = max(class_counts.values())\n",
    "class_weights = {class_id: max_count / count for class_id, count in class_counts.items()}\n",
    "weights = [class_weights[class_id] for class_id in sorted(class_weights.keys())]\n",
    "\n",
    "weights_tensor = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# 3. Use the weights in the loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()  # use this if data is not imbalanced\n",
    "\n",
    "# Add Learning Rate Scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "# Train the model\n",
    "best_f1 = 0.0  # for early stopping based on F1 score\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    training_start_time = time.time()  # Start measuring time\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    training_end_time = time.time()  # End measuring time\n",
    "    training_time = training_end_time - training_start_time  # Calculate elapsed time for training\n",
    "\n",
    "    model.eval()\n",
    "    testing_start_time = time.time()  # Start measuring time\n",
    "    predictions, true_labels = [], []\n",
    "    val_loss = 0  # to compute average validation loss for scheduler\n",
    "\n",
    "    for batch in test_loader:\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            predictions.extend(torch.argmax(outputs, dim=1).cpu().tolist())\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "    testing_end_time = time.time()  # End measuring time\n",
    "    testing_time = testing_end_time - testing_start_time  # Calculate elapsed time for testing\n",
    "\n",
    "    val_f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    scheduler.step(val_loss / len(test_loader))  # scheduler step based on avg val loss\n",
    "    report6 = classification_report(true_labels, predictions)\n",
    "    #print(f\"Epoch: {epoch}, F1 Score for sample2: {val_f1}\")\n",
    "    # Measure the time at the end of the epoch and calculate the total epoch time\n",
    "    print(f\"Epoch: {epoch}, Training Time: {training_time} seconds, Testing Time: {testing_time} seconds\")\n",
    "    \n",
    "    # Implementing early stopping based on F1 score\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        #torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= 3:\n",
    "            print(\"Early stopping\")\n",
    "            print(report6)\n",
    "            break\n",
    "            \n",
    "else:  # This block will be executed if the for loop completes normally, i.e., if early stopping does not occur.\n",
    "    print(\"Training completed.\")\n",
    "    print(report6)  # Print the classification report after the last epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Time: 178.0331208705902 seconds, Testing Time: 19.486204862594604 seconds\n",
      "Epoch: 1, Training Time: 168.6105773448944 seconds, Testing Time: 19.171525955200195 seconds\n",
      "Epoch: 2, Training Time: 168.56853222846985 seconds, Testing Time: 19.549827814102173 seconds\n",
      "Epoch: 3, Training Time: 169.33317685127258 seconds, Testing Time: 19.34743046760559 seconds\n",
      "Epoch: 4, Training Time: 168.88169169425964 seconds, Testing Time: 19.31159019470215 seconds\n",
      "Epoch: 5, Training Time: 168.58642506599426 seconds, Testing Time: 19.321823120117188 seconds\n",
      "Epoch: 6, Training Time: 168.25208640098572 seconds, Testing Time: 19.324920892715454 seconds\n",
      "Epoch: 7, Training Time: 168.42181491851807 seconds, Testing Time: 19.4970064163208 seconds\n",
      "Epoch: 8, Training Time: 167.69868302345276 seconds, Testing Time: 19.209219932556152 seconds\n",
      "Epoch: 9, Training Time: 167.69934964179993 seconds, Testing Time: 19.322603940963745 seconds\n",
      "Training completed.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75      1360\n",
      "           1       0.67      0.59      0.62       506\n",
      "           2       0.73      0.82      0.77       569\n",
      "           3       0.78      0.78      0.78       227\n",
      "           4       0.88      0.86      0.87       267\n",
      "           5       0.55      0.55      0.55       407\n",
      "           6       0.50      0.37      0.43       270\n",
      "           7       0.72      0.62      0.66       786\n",
      "           8       0.79      0.80      0.79       283\n",
      "           9       0.96      1.00      0.98        44\n",
      "\n",
      "    accuracy                           0.71      4719\n",
      "   macro avg       0.73      0.72      0.72      4719\n",
      "weighted avg       0.70      0.71      0.70      4719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##BiLSTM tuned MODEL FOR SAMPLE 1\n",
    "import warnings\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class AdjustedBiLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout=0.2):\n",
    "        super(AdjustedBiLSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Add this line to store the hidden_dim as an instance variable\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(2*hidden_dim, output_dim)  # Multiply by 2 because it's bidirectional\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Use the last hidden state for classification. We concatenate the last hidden state from both directions\n",
    "        output = self.fc(self.dropout(torch.cat((lstm_out[:, -1, :self.hidden_dim], lstm_out[:, 0, self.hidden_dim:]), dim=1)))\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate model\n",
    "model = AdjustedBiLSTMModel(vocab_size=tokenizer.vocab_size, embedding_dim=128, hidden_dim=256, output_dim=10, dropout=0.2).to(device)\n",
    "\n",
    "#model = AdjustedLSTMModel(vocab_size=tokenizer.vocab_size, embedding_dim=128, hidden_dim=256, output_dim=10, dropout=0.2).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(),lr=0.001)\n",
    "\n",
    "# If your dataset is imbalanced, compute class weights\n",
    "# weights = # Compute based on class distribution\n",
    "# criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "\n",
    "# Assuming `train_labels` is a list containing all the labels in your training dataset\n",
    "train_labels = [label for batch in train_loader for label in batch['labels'].tolist()]\n",
    "\n",
    "# 1. Compute class distribution\n",
    "class_counts = Counter(train_labels)\n",
    "\n",
    "# 2. Calculate the weights\n",
    "max_count = max(class_counts.values())\n",
    "class_weights = {class_id: max_count / count for class_id, count in class_counts.items()}\n",
    "weights = [class_weights[class_id] for class_id in sorted(class_weights.keys())]\n",
    "\n",
    "weights_tensor = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# 3. Use the weights in the loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()  # use this if data is not imbalanced\n",
    "\n",
    "# Add Learning Rate Scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "# Train the model\n",
    "best_f1 = 0.0  # for early stopping based on F1 score\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    training_start_time = time.time()  # Start measuring time\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    training_end_time = time.time()  # End measuring time\n",
    "    training_time = training_end_time - training_start_time  # Calculate elapsed time for training\n",
    "\n",
    "    model.eval()\n",
    "    testing_start_time = time.time()  # Start measuring time\n",
    "    predictions, true_labels = [], []\n",
    "    val_loss = 0  # to compute average validation loss for scheduler\n",
    "\n",
    "    for batch in test_loader:\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            predictions.extend(torch.argmax(outputs, dim=1).cpu().tolist())\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "    testing_end_time = time.time()  # End measuring time\n",
    "    testing_time = testing_end_time - testing_start_time  # Calculate elapsed time for testing\n",
    "\n",
    "    val_f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    scheduler.step(val_loss / len(test_loader))  # scheduler step based on avg val loss\n",
    "    report7 = classification_report(true_labels, predictions)\n",
    "    #print(f\"Epoch: {epoch}, F1 Score for sample2: {val_f1}\")\n",
    "    # Measure the time at the end of the epoch and calculate the total epoch time\n",
    "    print(f\"Epoch: {epoch}, Training Time: {training_time} seconds, Testing Time: {testing_time} seconds\")\n",
    "    \n",
    "    # Implementing early stopping based on F1 score\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        #torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= 3:\n",
    "            print(\"Early stopping\")\n",
    "            print(report7)\n",
    "            break\n",
    "            \n",
    "else:  # This block will be executed if the for loop completes normally, i.e., if early stopping does not occur.\n",
    "    print(\"Training completed.\")\n",
    "    print(report7)  # Print the classification report after the last epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Time: 5821.8458042144775 seconds, Testing Time: 523.3689856529236 seconds\n",
      "Epoch: 1, Training Time: 5841.6384217739105 seconds, Testing Time: 548.2840623855591 seconds\n",
      "Epoch: 2, Training Time: 2656.381799697876 seconds, Testing Time: 243.84410643577576 seconds\n",
      "Epoch: 3, Training Time: 2751.931289434433 seconds, Testing Time: 266.76108479499817 seconds\n",
      "Early stopping triggered.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      1360\n",
      "           1       0.71      0.87      0.78       506\n",
      "           2       0.90      0.77      0.83       569\n",
      "           3       0.87      0.88      0.87       227\n",
      "           4       0.96      0.96      0.96       267\n",
      "           5       0.77      0.75      0.76       407\n",
      "           6       0.78      0.69      0.73       270\n",
      "           7       0.85      0.82      0.83       786\n",
      "           8       0.90      0.87      0.88       283\n",
      "           9       1.00      1.00      1.00        44\n",
      "\n",
      "    accuracy                           0.84      4719\n",
      "   macro avg       0.86      0.85      0.85      4719\n",
      "weighted avg       0.85      0.84      0.84      4719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##BERT MODEL FOR SAMPLE 2\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BERTForClassification(10).to(device)  # replace NUM_CLASSES with the number of unique labels in your dataset\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 3\n",
    "best_valid_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    training_start_time = time.time()  # Start measuring time\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        inputs, attention_mask, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['labels'].to(device)\n",
    "        outputs = model(inputs, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    training_end_time = time.time()  # End measuring time\n",
    "    training_time = training_end_time - training_start_time  # Calculate elapsed time for training\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    testing_start_time = time.time()  # Start measuring time\n",
    "    predictions, true_labels = [], []\n",
    "    for batch in test_loader:\n",
    "        with torch.no_grad():\n",
    "            inputs, attention_mask, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['labels'].to(device)\n",
    "            outputs = model(inputs, attention_mask)\n",
    "            predictions.extend(torch.argmax(outputs, dim=1).cpu().tolist())\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "    testing_end_time = time.time()  # End measuring time\n",
    "    testing_time = testing_end_time - testing_start_time  # Calculate elapsed time for testing\n",
    "\n",
    "    val_f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    report8 = classification_report(true_labels, predictions)\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Training Time: {training_time} seconds, Testing Time: {testing_time} seconds\")\n",
    "    # Early stopping logic\n",
    "    if val_f1 < best_valid_loss:\n",
    "        best_valid_loss = val_f1\n",
    "        counter = 0\n",
    "        #torch.save(model.state_dict(), 'best_model_bert2.pkl')  # Save the model\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            print(report8)\n",
    "            break\n",
    "            \n",
    "else:  # This block will be executed if the for loop completes normally, i.e., if early stopping does not occur.\n",
    "    print(\"Training completed.\")\n",
    "    print(report8)  # Print the classification report after the last epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## working on full dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(train_encodings3, train_df3['labels'].tolist())\n",
    "test_dataset = TextDataset(test_encodings3, test_df3['labels'].tolist())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Time: 81.18975806236267 seconds, Testing Time: 12.927451133728027 seconds\n",
      "Epoch: 1, Training Time: 81.82534098625183 seconds, Testing Time: 13.028075218200684 seconds\n",
      "Epoch: 2, Training Time: 81.76583075523376 seconds, Testing Time: 12.9928457736969 seconds\n",
      "Epoch: 3, Training Time: 82.368008852005 seconds, Testing Time: 13.084489107131958 seconds\n",
      "Epoch: 4, Training Time: 82.09669613838196 seconds, Testing Time: 12.963333368301392 seconds\n",
      "Epoch: 5, Training Time: 82.13156628608704 seconds, Testing Time: 13.038267374038696 seconds\n",
      "Epoch: 6, Training Time: 81.87105989456177 seconds, Testing Time: 13.057200908660889 seconds\n",
      "Epoch: 7, Training Time: 82.07426834106445 seconds, Testing Time: 12.942949295043945 seconds\n",
      "Epoch: 8, Training Time: 82.19202995300293 seconds, Testing Time: 13.100719690322876 seconds\n",
      "Epoch: 9, Training Time: 82.12648129463196 seconds, Testing Time: 12.895895004272461 seconds\n",
      "Training completed.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.36      0.36      1953\n",
      "           1       0.13      0.07      0.09       705\n",
      "           2       0.42      0.56      0.48       826\n",
      "           3       0.22      0.08      0.12       333\n",
      "           4       0.09      0.10      0.09       364\n",
      "           5       0.10      0.08      0.09       560\n",
      "           6       0.11      0.07      0.08       436\n",
      "           7       0.23      0.30      0.26      1098\n",
      "           8       0.10      0.10      0.10       402\n",
      "           9       0.11      0.33      0.16        64\n",
      "\n",
      "    accuracy                           0.26      6741\n",
      "   macro avg       0.19      0.20      0.18      6741\n",
      "weighted avg       0.24      0.26      0.25      6741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RNN Tuned MODEL FOR SAMPLE 3\n",
    "\n",
    "import warnings\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class AdjustedRNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout=0.4):\n",
    "        super(AdjustedRNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)  # Use nn.RNN instead of nn.LSTM\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        rnn_out, _ = self.rnn(embedded)  # Use rnn_out instead of lstm_out\n",
    "        # Use the last hidden state for classification\n",
    "        output = self.fc(self.dropout(rnn_out[:, -1, :]))\n",
    "        return output\n",
    "\n",
    "# Instantiate model\n",
    "model = AdjustedRNNModel(vocab_size=tokenizer.vocab_size, embedding_dim=128, hidden_dim=256, output_dim=10, dropout=0.4).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.00002)\n",
    "\n",
    "\n",
    "# Assuming `train_labels` is a list containing all the labels in your training dataset\n",
    "train_labels = [label for batch in train_loader for label in batch['labels'].tolist()]\n",
    "\n",
    "# 1. Compute class distribution\n",
    "class_counts = Counter(train_labels)\n",
    "\n",
    "# 2. Calculate the weights\n",
    "max_count = max(class_counts.values())\n",
    "class_weights = {class_id: max_count / count for class_id, count in class_counts.items()}\n",
    "weights = [class_weights[class_id] for class_id in sorted(class_weights.keys())]\n",
    "\n",
    "weights_tensor = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# 3. Use the weights in the loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()  # use this if data is not imbalanced\n",
    "\n",
    "# Add Learning Rate Scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "# Train the model\n",
    "best_f1 = 0.0  # for early stopping based on F1 score\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Measure the time at the start of the epoch\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    training_start_time = time.time()  # Start measuring time\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    training_end_time = time.time()  # End measuring time\n",
    "    training_time = training_end_time - training_start_time  # Calculate elapsed time for training\n",
    "\n",
    "    model.eval()\n",
    "    testing_start_time = time.time()  # Start measuring time\n",
    "    predictions, true_labels = [], []\n",
    "    val_loss = 0  # to compute average validation loss for scheduler\n",
    "\n",
    "    for batch in test_loader:\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            predictions.extend(torch.argmax(outputs, dim=1).cpu().tolist())\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "    testing_end_time = time.time()  # End measuring time\n",
    "    testing_time = testing_end_time - testing_start_time  # Calculate elapsed time for testing\n",
    "\n",
    "    val_f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    scheduler.step(val_loss / len(test_loader))  # scheduler step based on avg val loss\n",
    "    report9 = classification_report(true_labels, predictions)\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Training Time: {training_time} seconds, Testing Time: {testing_time} seconds\")\n",
    "    \n",
    "    # Implementing early stopping based on F1 score\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), '/workspace/outputs/simplernn_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= 3:\n",
    "            print(\"Early stopping\")\n",
    "            print(report9)\n",
    "            break\n",
    "            \n",
    "else:  # This block will be executed if the for loop completes normally, i.e., if early stopping does not occur.\n",
    "    print(\"Training completed.\")\n",
    "    print(report9)  # Print the classification report after the last epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Time: 14.653367042541504 seconds, Testing Time: 1.7771806716918945 seconds\n",
      "Epoch: 1, Training Time: 14.599278688430786 seconds, Testing Time: 1.7768876552581787 seconds\n",
      "Epoch: 2, Training Time: 14.60213828086853 seconds, Testing Time: 1.7757465839385986 seconds\n",
      "Epoch: 3, Training Time: 14.596824407577515 seconds, Testing Time: 1.7774076461791992 seconds\n",
      "Epoch: 4, Training Time: 14.605844736099243 seconds, Testing Time: 1.7760374546051025 seconds\n",
      "Epoch: 5, Training Time: 14.607850313186646 seconds, Testing Time: 1.7770261764526367 seconds\n",
      "Epoch: 6, Training Time: 14.605615377426147 seconds, Testing Time: 1.7768173217773438 seconds\n",
      "Epoch: 7, Training Time: 14.60275912284851 seconds, Testing Time: 1.7767760753631592 seconds\n",
      "Early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.33      0.35      1953\n",
      "           1       0.10      0.00      0.01       705\n",
      "           2       0.29      0.47      0.36       826\n",
      "           3       0.09      0.16      0.12       333\n",
      "           4       0.10      0.06      0.08       364\n",
      "           5       0.11      0.12      0.11       560\n",
      "           6       0.06      0.02      0.03       436\n",
      "           7       0.22      0.23      0.22      1098\n",
      "           8       0.09      0.17      0.12       402\n",
      "           9       0.09      0.17      0.11        64\n",
      "\n",
      "    accuracy                           0.22      6741\n",
      "   macro avg       0.15      0.17      0.15      6741\n",
      "weighted avg       0.22      0.22      0.21      6741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RNN Tuned MODEL FOR SAMPLE 3\n",
    "\n",
    "import warnings\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class AdjustedRNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout=0.4):\n",
    "        super(AdjustedRNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)  # Use nn.RNN instead of nn.LSTM\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        rnn_out, _ = self.rnn(embedded)  # Use rnn_out instead of lstm_out\n",
    "        # Use the last hidden state for classification\n",
    "        output = self.fc(self.dropout(rnn_out[:, -1, :]))\n",
    "        return output\n",
    "\n",
    "# Instantiate model\n",
    "model = AdjustedRNNModel(vocab_size=tokenizer.vocab_size, embedding_dim=128, hidden_dim=256, output_dim=10, dropout=0.4).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.00002)\n",
    "\n",
    "\n",
    "# Assuming `train_labels` is a list containing all the labels in your training dataset\n",
    "train_labels = [label for batch in train_loader for label in batch['labels'].tolist()]\n",
    "\n",
    "# 1. Compute class distribution\n",
    "class_counts = Counter(train_labels)\n",
    "\n",
    "# 2. Calculate the weights\n",
    "max_count = max(class_counts.values())\n",
    "class_weights = {class_id: max_count / count for class_id, count in class_counts.items()}\n",
    "weights = [class_weights[class_id] for class_id in sorted(class_weights.keys())]\n",
    "\n",
    "weights_tensor = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# 3. Use the weights in the loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()  # use this if data is not imbalanced\n",
    "\n",
    "# Add Learning Rate Scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "# Train the model\n",
    "best_f1 = 0.0  # for early stopping based on F1 score\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Measure the time at the start of the epoch\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    training_start_time = time.time()  # Start measuring time\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    training_end_time = time.time()  # End measuring time\n",
    "    training_time = training_end_time - training_start_time  # Calculate elapsed time for training\n",
    "\n",
    "    model.eval()\n",
    "    testing_start_time = time.time()  # Start measuring time\n",
    "    predictions, true_labels = [], []\n",
    "    val_loss = 0  # to compute average validation loss for scheduler\n",
    "\n",
    "    for batch in test_loader:\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            predictions.extend(torch.argmax(outputs, dim=1).cpu().tolist())\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "    testing_end_time = time.time()  # End measuring time\n",
    "    testing_time = testing_end_time - testing_start_time  # Calculate elapsed time for testing\n",
    "\n",
    "    val_f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    scheduler.step(val_loss / len(test_loader))  # scheduler step based on avg val loss\n",
    "    report9 = classification_report(true_labels, predictions)\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Training Time: {training_time} seconds, Testing Time: {testing_time} seconds\")\n",
    "    \n",
    "    # Implementing early stopping based on F1 score\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), '/workspace/outputs/simplernn_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= 3:\n",
    "            print(\"Early stopping\")\n",
    "            print(report9)\n",
    "            break\n",
    "            \n",
    "else:  # This block will be executed if the for loop completes normally, i.e., if early stopping does not occur.\n",
    "    print(\"Training completed.\")\n",
    "    print(report9)  # Print the classification report after the last epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Time: 203.02118039131165 seconds, Testing Time: 26.80011796951294 seconds\n",
      "Epoch: 1, Training Time: 201.98398566246033 seconds, Testing Time: 26.68457841873169 seconds\n",
      "Epoch: 2, Training Time: 202.658305644989 seconds, Testing Time: 26.826446771621704 seconds\n",
      "Epoch: 3, Training Time: 203.49253058433533 seconds, Testing Time: 26.995861530303955 seconds\n",
      "Epoch: 4, Training Time: 203.52809619903564 seconds, Testing Time: 26.81853699684143 seconds\n",
      "Epoch: 5, Training Time: 202.4718325138092 seconds, Testing Time: 26.83898162841797 seconds\n",
      "Epoch: 6, Training Time: 202.39271092414856 seconds, Testing Time: 26.576830863952637 seconds\n",
      "Epoch: 7, Training Time: 202.02381110191345 seconds, Testing Time: 26.941951036453247 seconds\n",
      "Epoch: 8, Training Time: 203.0194296836853 seconds, Testing Time: 26.829503059387207 seconds\n",
      "Epoch: 9, Training Time: 203.93054628372192 seconds, Testing Time: 26.924782276153564 seconds\n",
      "Training completed.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83      1953\n",
      "           1       0.77      0.74      0.76       705\n",
      "           2       0.83      0.85      0.84       826\n",
      "           3       0.86      0.89      0.87       333\n",
      "           4       0.96      0.96      0.96       364\n",
      "           5       0.67      0.76      0.71       560\n",
      "           6       0.68      0.71      0.70       436\n",
      "           7       0.83      0.72      0.77      1098\n",
      "           8       0.86      0.80      0.83       402\n",
      "           9       1.00      0.98      0.99        64\n",
      "\n",
      "    accuracy                           0.81      6741\n",
      "   macro avg       0.83      0.83      0.83      6741\n",
      "weighted avg       0.81      0.81      0.81      6741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##LSTM tined MODEL FOR SAMPLE 3\n",
    "import warnings\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class AdjustedLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout=0.2):\n",
    "        super(AdjustedLSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Use the last hidden state for classification\n",
    "        output = self.fc(self.dropout(lstm_out[:, -1, :]))\n",
    "        return output\n",
    "\n",
    "# Instantiate model\n",
    "model = AdjustedLSTMModel(vocab_size=tokenizer.vocab_size, embedding_dim=128, hidden_dim=256, output_dim=10, dropout=0.2).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(),lr=0.001)\n",
    "\n",
    "# If your dataset is imbalanced, compute class weights\n",
    "# weights = # Compute based on class distribution\n",
    "# criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "\n",
    "# Assuming `train_labels` is a list containing all the labels in your training dataset\n",
    "train_labels = [label for batch in train_loader for label in batch['labels'].tolist()]\n",
    "\n",
    "# 1. Compute class distribution\n",
    "class_counts = Counter(train_labels)\n",
    "\n",
    "# 2. Calculate the weights\n",
    "max_count = max(class_counts.values())\n",
    "class_weights = {class_id: max_count / count for class_id, count in class_counts.items()}\n",
    "weights = [class_weights[class_id] for class_id in sorted(class_weights.keys())]\n",
    "\n",
    "weights_tensor = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# 3. Use the weights in the loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()  # use this if data is not imbalanced\n",
    "\n",
    "# Add Learning Rate Scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "# Train the model\n",
    "best_f1 = 0.0  # for early stopping based on F1 score\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    training_start_time = time.time()  # Start measuring time\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    training_end_time = time.time()  # End measuring time\n",
    "    training_time = training_end_time - training_start_time  # Calculate elapsed time for training\n",
    "\n",
    "    model.eval()\n",
    "    testing_start_time = time.time()  # Start measuring time\n",
    "    predictions, true_labels = [], []\n",
    "    val_loss = 0  # to compute average validation loss for scheduler\n",
    "\n",
    "    for batch in test_loader:\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            predictions.extend(torch.argmax(outputs, dim=1).cpu().tolist())\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "    testing_end_time = time.time()  # End measuring time\n",
    "    testing_time = testing_end_time - testing_start_time  # Calculate elapsed time for testing\n",
    "\n",
    "    val_f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    scheduler.step(val_loss / len(test_loader))  # scheduler step based on avg val loss\n",
    "    report10 = classification_report(true_labels, predictions)\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Training Time: {training_time} seconds, Testing Time: {testing_time} seconds\")\n",
    "    \n",
    "    # Implementing early stopping based on F1 score\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), '/workspace/outputs/lstm_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= 3:\n",
    "            print(\"Early stopping\")\n",
    "            print(report10)\n",
    "            break\n",
    "            \n",
    "else:  # This block will be executed if the for loop completes normally, i.e., if early stopping does not occur.\n",
    "    print(\"Training completed.\")\n",
    "    print(report10)  # Print the classification report after the last epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Time: 241.0042974948883 seconds, Testing Time: 27.989733457565308 seconds\n",
      "Epoch: 1, Training Time: 241.36780452728271 seconds, Testing Time: 27.740985870361328 seconds\n",
      "Epoch: 2, Training Time: 257.99055075645447 seconds, Testing Time: 29.94828462600708 seconds\n",
      "Epoch: 3, Training Time: 260.51057410240173 seconds, Testing Time: 27.734104871749878 seconds\n",
      "Epoch: 4, Training Time: 241.2057478427887 seconds, Testing Time: 27.58629560470581 seconds\n",
      "Epoch: 5, Training Time: 241.07780075073242 seconds, Testing Time: 27.801841020584106 seconds\n",
      "Epoch: 6, Training Time: 240.1743197441101 seconds, Testing Time: 27.680588006973267 seconds\n",
      "Epoch: 7, Training Time: 240.85477781295776 seconds, Testing Time: 27.55038833618164 seconds\n",
      "Epoch: 8, Training Time: 240.6198766231537 seconds, Testing Time: 27.818445920944214 seconds\n",
      "Epoch: 9, Training Time: 240.6929953098297 seconds, Testing Time: 27.44154381752014 seconds\n",
      "Training completed.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1953\n",
      "           1       0.72      0.73      0.73       705\n",
      "           2       0.81      0.82      0.81       826\n",
      "           3       0.89      0.80      0.84       333\n",
      "           4       0.92      0.93      0.93       364\n",
      "           5       0.65      0.59      0.62       560\n",
      "           6       0.63      0.54      0.58       436\n",
      "           7       0.72      0.81      0.77      1098\n",
      "           8       0.83      0.87      0.85       402\n",
      "           9       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           0.78      6741\n",
      "   macro avg       0.80      0.79      0.80      6741\n",
      "weighted avg       0.78      0.78      0.78      6741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##BiLSTM tuned MODEL FOR SAMPLE 3\n",
    "import warnings\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class AdjustedBiLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout=0.2):\n",
    "        super(AdjustedBiLSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Add this line to store the hidden_dim as an instance variable\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(2*hidden_dim, output_dim)  # Multiply by 2 because it's bidirectional\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Use the last hidden state for classification. We concatenate the last hidden state from both directions\n",
    "        output = self.fc(self.dropout(torch.cat((lstm_out[:, -1, :self.hidden_dim], lstm_out[:, 0, self.hidden_dim:]), dim=1)))\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate model\n",
    "model = AdjustedBiLSTMModel(vocab_size=tokenizer.vocab_size, embedding_dim=128, hidden_dim=256, output_dim=10, dropout=0.2).to(device)\n",
    "\n",
    "#model = AdjustedLSTMModel(vocab_size=tokenizer.vocab_size, embedding_dim=128, hidden_dim=256, output_dim=10, dropout=0.2).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(),lr=0.001)\n",
    "\n",
    "# If your dataset is imbalanced, compute class weights\n",
    "# weights = # Compute based on class distribution\n",
    "# criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "\n",
    "# Assuming `train_labels` is a list containing all the labels in your training dataset\n",
    "train_labels = [label for batch in train_loader for label in batch['labels'].tolist()]\n",
    "\n",
    "# 1. Compute class distribution\n",
    "class_counts = Counter(train_labels)\n",
    "\n",
    "# 2. Calculate the weights\n",
    "max_count = max(class_counts.values())\n",
    "class_weights = {class_id: max_count / count for class_id, count in class_counts.items()}\n",
    "weights = [class_weights[class_id] for class_id in sorted(class_weights.keys())]\n",
    "\n",
    "weights_tensor = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# 3. Use the weights in the loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()  # use this if data is not imbalanced\n",
    "\n",
    "# Add Learning Rate Scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "# Train the model\n",
    "best_f1 = 0.0  # for early stopping based on F1 score\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    training_start_time = time.time()  # Start measuring time\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    training_end_time = time.time()  # End measuring time\n",
    "    training_time = training_end_time - training_start_time  # Calculate elapsed time for training\n",
    "\n",
    "    model.eval()\n",
    "    testing_start_time = time.time()  # Start measuring time\n",
    "    predictions, true_labels = [], []\n",
    "    val_loss = 0  # to compute average validation loss for scheduler\n",
    "\n",
    "    for batch in test_loader:\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            predictions.extend(torch.argmax(outputs, dim=1).cpu().tolist())\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "    testing_end_time = time.time()  # End measuring time\n",
    "    testing_time = testing_end_time - testing_start_time  # Calculate elapsed time for testing\n",
    "\n",
    "    val_f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    scheduler.step(val_loss / len(test_loader))  # scheduler step based on avg val loss\n",
    "    report11 = classification_report(true_labels, predictions)\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Training Time: {training_time} seconds, Testing Time: {testing_time} seconds\")\n",
    "    \n",
    "    # Implementing early stopping based on F1 score\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), '/workspace/outputs/bilstm_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= 3:\n",
    "            print(\"Early stopping\")\n",
    "            print(report11)\n",
    "            break\n",
    "\n",
    "else:  # This block will be executed if the for loop completes normally, i.e., if early stopping does not occur.\n",
    "    print(\"Training completed.\")\n",
    "    print(report11)  # Print the classification report after the last epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Time: 3786.356432914734 seconds, Testing Time: 348.7625558376312 seconds\n",
      "Epoch: 1, Training Time: 4035.283329963684 seconds, Testing Time: 382.64703011512756 seconds\n",
      "Epoch: 2, Training Time: 5931.065721035004 seconds, Testing Time: 742.067969083786 seconds\n",
      "Epoch: 3, Training Time: 8218.446682214737 seconds, Testing Time: 745.0084149837494 seconds\n",
      "Early stopping triggered.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91      1953\n",
      "           1       0.84      0.84      0.84       705\n",
      "           2       0.86      0.88      0.87       826\n",
      "           3       0.89      0.86      0.88       333\n",
      "           4       0.96      0.98      0.97       364\n",
      "           5       0.79      0.80      0.80       560\n",
      "           6       0.70      0.78      0.74       436\n",
      "           7       0.89      0.84      0.87      1098\n",
      "           8       0.94      0.88      0.91       402\n",
      "           9       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           0.87      6741\n",
      "   macro avg       0.88      0.88      0.88      6741\n",
      "weighted avg       0.87      0.87      0.87      6741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##BERT MODEL FOR SAMPLE 1\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BERTForClassification(10).to(device)  # replace NUM_CLASSES with the number of unique labels in your dataset\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 3\n",
    "best_valid_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    training_start_time = time.time()  # Start measuring time\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        inputs, attention_mask, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['labels'].to(device)\n",
    "        outputs = model(inputs, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    training_end_time = time.time()  # End measuring time\n",
    "    training_time = training_end_time - training_start_time  # Calculate elapsed time for training\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    testing_start_time = time.time()  # Start measuring time\n",
    "    predictions, true_labels = [], []\n",
    "    for batch in test_loader:\n",
    "        with torch.no_grad():\n",
    "            inputs, attention_mask, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['labels'].to(device)\n",
    "            outputs = model(inputs, attention_mask)\n",
    "            predictions.extend(torch.argmax(outputs, dim=1).cpu().tolist())\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "    testing_end_time = time.time()  # End measuring time\n",
    "    testing_time = testing_end_time - testing_start_time  # Calculate elapsed time for testing\n",
    "\n",
    "    val_f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    report12 = classification_report(true_labels, predictions)\n",
    "    print(f\"Epoch: {epoch}, Training Time: {training_time} seconds, Testing Time: {testing_time} seconds\")\n",
    "    \n",
    "    # Early stopping logic\n",
    "    if val_f1 < best_valid_loss:\n",
    "        best_valid_loss = val_f1\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), '/workspace/outputs/Bert_model.pth')  # Save the model\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            print(report12)\n",
    "            break\n",
    "\n",
    "else:  # This block will be executed if the for loop completes normally, i.e., if early stopping does not occur.\n",
    "    print(\"Training completed.\")\n",
    "    print(report12)  # Print the classification report after the last epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
